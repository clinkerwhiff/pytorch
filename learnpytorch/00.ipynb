{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Fundamentals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor\n",
    "\n",
    "Tensors are multi-dimensional matrices.  \n",
    "PyTorch tensors are objects of the `torch.Tensor` class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scalar\n",
    "\n",
    "Scalars are zero-dimensional tensors, or in other words, tensors that hold a single element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar = torch.tensor(7)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `item()` method returns the singular element of a scalar.  \n",
    "It only works for scalars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector\n",
    "\n",
    "Vectors are one-dimensional tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = torch.tensor([5, 3])\n",
    "vector.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix\n",
    "\n",
    "Matrices are two-dimensional tensors.  \n",
    "It is conventional to name matrices and tensors using upppercase, whereas scalars and vectors are named using lowercase.  \n",
    "The terms matrix and tensor are often used interchangably."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX = torch.tensor([[1, 2], [3, 4]])\n",
    "MATRIX.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialising tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.1635, 0.4552, 0.0026, 0.1222],\n",
       "         [0.5348, 0.8299, 0.7334, 0.9770],\n",
       "         [0.1373, 0.3247, 0.7063, 0.7918]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor = torch.rand(size=(3, 4))\n",
    "random_tensor, random_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros = torch.zeros(size=(3, 4))\n",
    "zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones = torch.ones(size=(3, 4))\n",
    "ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_to_ten = torch.arange(start=0, end=10, step=1)\n",
    "zero_to_ten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a likeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros = torch.zeros_like(zero_to_ten)\n",
    "ones = torch.ones_like(zero_to_ten)\n",
    "zeros, ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datatypes\n",
    "\n",
    "The most common and default datatype is `torch.float32` or `torch.float`.  \n",
    "`torch.float16` is also called `torch.half`.  \n",
    "`torch.float64` is also called `torch.double`.  \n",
    "The default value of the `dtype` attribute is `torch.float32`.  \n",
    "The `requires_grad` attribute is set to `True` if we want the operations on the tensor to be recorded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3]), torch.float16, device(type='cpu'))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_tensor = torch.tensor([3.0, 6.0, 9.0], dtype=torch.float16, device=None, requires_grad=False)\n",
    "float_16_tensor.shape, float_16_tensor.dtype, float_16_tensor.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting information from tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4584, 0.6134, 0.1268, 0.4145],\n",
      "        [0.5393, 0.5050, 0.2049, 0.0521],\n",
      "        [0.0531, 0.6261, 0.4240, 0.4981]])\n",
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "Device of tensor: cpu\n"
     ]
    }
   ],
   "source": [
    "sample_tensor = torch.rand(3, 4)\n",
    "print(sample_tensor)\n",
    "print(f\"Shape of tensor: {sample_tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {sample_tensor.dtype}\")\n",
    "print(f\"Device of tensor: {sample_tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operations on tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.tensor([1, 2, 3])\n",
    "tensor + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 4, 9])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor * tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix multiplication\n",
    "\n",
    "There are two rules for performing matrix multiplication.  \n",
    "The inner dimensions must match - `(3, 2) @ (2, 4)` works as the inner dimensions are both `2`.  \n",
    "The resulting matrix has the shape of the outer dimensions - `(3, 2) @ (2, 4)` results in a matrix of dimensions `(3, 4)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0443, 0.0967, 0.0794, 0.0809],\n",
       "        [0.5437, 0.9895, 0.8872, 0.5852],\n",
       "        [0.2664, 0.7250, 0.5410, 0.7851]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.rand(3, 2)\n",
    "B = torch.rand(2, 4)\n",
    "A @ B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0443, 0.0967, 0.0794, 0.0809],\n",
       "        [0.5437, 0.9895, 0.8872, 0.5852],\n",
       "        [0.2664, 0.7250, 0.5410, 0.7851]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.tensor([1, 2, 3])\n",
    "torch.matmul(t, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8957, 0.4147, 0.3146],\n",
       "        [0.6063, 0.2824, 0.2141],\n",
       "        [0.3311, 0.2969, 0.2105]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.rand(3, 2)\n",
    "B = torch.rand(3, 2)\n",
    "torch.mm(A, B.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch.nn.Linear` implements matrix multiplication between an input layer `x` and a weights matrix `A`.  \n",
    "The operation it performs is represented by the equation $y = x \\cdot A^T + b$.\n",
    "The `manual_seed()` method is used for seeding, to ensure that the code that follows always produces the same output, despite the linear layer relying on random weights and biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.8126, 0.8936, 0.6832, 0.6857, 1.4842, 0.0325],\n",
       "        [3.6429, 1.8705, 2.1661, 2.1521, 2.2470, 1.0608],\n",
       "        [5.4732, 2.8474, 3.6489, 3.6184, 3.0098, 2.0891]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(30)\n",
    "linear = torch.nn.Linear(in_features=2, out_features=6)\n",
    "x = torch.tensor([[1, 2], [3, 4], [5, 6]], dtype=torch.float32)\n",
    "linear(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregations\n",
    "\n",
    "Some methods such as `mean()` require tensors to be of a certain dataype (such as `torch.float32`).  \n",
    "The returned result of these methods is in the form of a zero-dimensional tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum: 0\n",
      "Maximum: 90\n",
      "Mean: 45.0\n",
      "Sum: 450\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(0, 100, 10)\n",
    "print(f\"Minimum: {x.min()}\")\n",
    "print(f\"Maximum: {x.max()}\")\n",
    "print(f\"Mean: {x.type(torch.float32).mean()}\")\n",
    "print(f\"Sum: {x.sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same operations can be performed as `torch` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(90), tensor(45.), tensor(450))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.min(x), torch.max(x), torch.mean(x.type(torch.float32)), torch.sum(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Position where maximum element occurs: 9\n",
      "Position where minimum element occurs: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Position where maximum element occurs: {x.argmax()}\")\n",
    "print(f\"Position where minimum element occurs: {x.argmin()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0., 10., 20., 30., 40., 50., 60., 70., 80., 90.])\n",
      "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90], dtype=torch.int8)\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.arange(0.0, 100.0, 10.0)\n",
    "print(tensor)\n",
    "tensor = tensor.type(torch.int8)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping versus creating a view\n",
    "\n",
    "The `reshape()` method tries to create a tensor which is a copy of the original tensor.  \n",
    "The `view()` method tries to create a tensor which shares the same underlying memory as the original tensor.  \n",
    "To ensure that an entirely new tensor is created, the `clone()` method is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 7, 4, 5, 7])\n",
      "tensor([[1, 2, 7],\n",
      "        [4, 5, 7]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1, 2, 3, 4, 5, 6])\n",
    "y = x.reshape(2, 3)\n",
    "y[:, 2] = 7\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 9, 4, 5, 9])\n",
      "tensor([[1, 2, 9],\n",
      "        [4, 5, 9]])\n"
     ]
    }
   ],
   "source": [
    "z = x.view(2, 3)\n",
    "z[:, 2] = 9\n",
    "print(x)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 9, 4, 5, 9])\n",
      "tensor([[1, 2, 8],\n",
      "        [4, 5, 8]])\n"
     ]
    }
   ],
   "source": [
    "w = x.reshape(2, 3).clone()\n",
    "w[:, 2] = 8\n",
    "print(x)\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other operations on tensors\n",
    "\n",
    "The `dim` attribute of the `stack()` method determines the dimension along which the tensors are stacked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2, 3, 4],\n",
      "        [0, 1, 2, 3, 4],\n",
      "        [0, 1, 2, 3, 4],\n",
      "        [0, 1, 2, 3, 4]])\n",
      "tensor([[0, 0, 0, 0],\n",
      "        [1, 1, 1, 1],\n",
      "        [2, 2, 2, 2],\n",
      "        [3, 3, 3, 3],\n",
      "        [4, 4, 4, 4]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(0, 5, 1)\n",
    "a = torch.stack([x, x, x, x], dim=0)\n",
    "print(a)\n",
    "b = torch.stack([x, x, x, x], dim=1)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "tensor([[1, 4],\n",
      "        [2, 5],\n",
      "        [3, 6]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1, 2, 3])\n",
    "y = torch.tensor([4, 5, 6])\n",
    "print(torch.stack([x, y], dim = 0))\n",
    "print(torch.stack([x, y], dim = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `squeeze()` method gets rid of all single-entried dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 1, 2])\n",
      "torch.Size([3, 2])\n",
      "torch.Size([1, 3, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(1, 3, 1, 2)\n",
    "print(tensor.shape)\n",
    "tensor = tensor.squeeze()\n",
    "print(tensor.shape)\n",
    "tensor = tensor.unsqueeze(dim=0)\n",
    "tensor = tensor.unsqueeze(dim=2)\n",
    "print(tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `permute` method is used for re-arranging tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 4],\n",
      "        [2, 5],\n",
      "        [3, 6]])\n",
      "torch.Size([3, 2])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "x = x.permute(1, 0)\n",
    "print(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([200, 200, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(3, 200, 200)\n",
    "x = x.permute(1, 2, 0)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 2, 3],\n",
      "         [4, 5, 6],\n",
      "         [7, 8, 9]]])\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n",
      "tensor([1, 2, 3])\n",
      "tensor([2, 5, 8])\n"
     ]
    }
   ],
   "source": [
    "grid = torch.arange(1, 10, 1).reshape(1, 3, 3)\n",
    "print(grid)\n",
    "print(grid[0])\n",
    "print(grid[0][0])\n",
    "print(grid[0, :, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors and NumPy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 2. 3. 4. 5. 6. 7. 8. 9.]\n",
      "tensor([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.], dtype=torch.float64)\n",
      "[0. 1. 2. 3. 4. 5. 6. 7. 8. 9.]\n"
     ]
    }
   ],
   "source": [
    "array = np.arange(0.0, 10.0)\n",
    "print(array)\n",
    "tensor = torch.from_numpy(array)\n",
    "print(tensor)\n",
    "array = tensor.numpy()\n",
    "print(array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seeding\n",
    "\n",
    "`torch.manual_seed()` is used to set the seed for random number generation on all devices.  \n",
    "`torch.random.manual_seed()` is used to seed the CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9007, 0.7464, 0.4716, 0.8738],\n",
      "        [0.7403, 0.7840, 0.8946, 0.6238],\n",
      "        [0.4276, 0.8421, 0.7454, 0.6181]])\n",
      "tensor([[0.9007, 0.7464, 0.4716, 0.8738],\n",
      "        [0.7403, 0.7840, 0.8946, 0.6238],\n",
      "        [0.4276, 0.8421, 0.7454, 0.6181]])\n",
      "tensor([[True, True, True, True],\n",
      "        [True, True, True, True],\n",
      "        [True, True, True, True]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(seed=30)\n",
    "a = torch.rand(3, 4)\n",
    "print(a)\n",
    "torch.random.manual_seed(seed=30)\n",
    "b = torch.rand(3, 4)\n",
    "print(b)\n",
    "print(a == b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `to()` method puts a tensor on a particular device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8883, 0.4127],\n",
       "        [0.1748, 0.3426]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.rand(2, 2)\n",
    "tensor.to(device)\n",
    "tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `cpu()` method puts a tensor on the CPU.  \n",
    "One reason for having to put a tensor on the CPU is to make it compatible with NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.88825244, 0.41274506],\n",
       "       [0.17482036, 0.3426432 ]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = tensor.cpu().numpy()\n",
    "tensor"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
